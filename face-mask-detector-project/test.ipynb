{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnVSSVVsIZcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "28279ee9-a8cc-4352-e8a5-06037f05692c"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/M.Learning/\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP_5rZb6Ivaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_model(\"./model2-003.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDsHnSZPJiTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_dict={0:'without mask',1:'mask'}\n",
        "color_dict={0:(0,0,255),1:(0,255,0)}\n",
        "\n",
        "size = 4\n",
        "webcam = cv2.VideoCapture(0) #Use camera 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFFqjSWdJkzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We load the xml file\n",
        "classifier = cv2.CascadeClassifier('C:\\\\Users\\\\nvtda\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eMLaXApVNF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "69e551d6-f120-4f6e-e285-d3b2bb89db4b"
      },
      "source": [
        "while True:\n",
        "    (rval, im) = webcam.read()\n",
        "    im=cv2.flip(im,1,1) #Flip to act as a mirror\n",
        "\n",
        "    # Resize the image to speed up detection\n",
        "    mini = cv2.resize(im, (im.shape[1] // 4, im.shape[0] // 4))\n",
        "\n",
        "    # detect MultiScale / faces \n",
        "    faces = classifier.detectMultiScale(mini)\n",
        "\n",
        "    # Draw rectangles around each face\n",
        "    for f in faces:\n",
        "        (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
        "        #Save just the rectangle faces in SubRecFaces\n",
        "        face_img = im[y:y+h, x:x+w]\n",
        "        resized=cv2.resize(face_img,(150,150))\n",
        "        normalized=resized/255.0\n",
        "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
        "        reshaped = np.vstack([reshaped])\n",
        "        result=model.predict(reshaped)\n",
        "        #print(result)\n",
        "        \n",
        "        label=np.argmax(result,axis=1)[0]\n",
        "      \n",
        "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
        "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1)\n",
        "        cv2.putText(im, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "        \n",
        "    # Show the image\n",
        "    cv2.imshow('LIVE',   im)\n",
        "    key = cv2.waitKey(10)\n",
        "    # if Esc key is press then break out of the loop \n",
        "    if key == 27: #The Esc key\n",
        "        break\n",
        "# Stop video\n",
        "webcam.release()\n",
        "\n",
        "# Close all started windows\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0e1bee38eb80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Resize the image to speed up detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# detect MultiScale / faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}